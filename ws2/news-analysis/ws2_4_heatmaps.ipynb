{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyses the data pre-processed in the `ws2_2_topic_modelling` notebook. \n",
    "\n",
    "Specifically, we look at:\n",
    "1. The number of articles published every day. We inspect how the average number of publications has been affected due to COVID-19.\n",
    "2. The number of articles published every day, <strong>per topic</strong>. We repeat the same experiment as the previous one but we go one step further and look at the impact of COVID on each separate topic.\n",
    "3. The sentiments conveyed in the articles published every day, <strong>per topic</strong>. We repeat once again the same experiment but we go even further by looking at the evolution of the sentiments in each separate topic.\n",
    "\n",
    "\n",
    "#### Input:\n",
    "\n",
    "ws_2_article_topic_<strong>XX</strong>.csv produced by the `ws2_2_topic_modelling` notebook:\n",
    "\n",
    "where <strong>XX</strong> is the optimal number of topics. The dataset is structured in 9 columns: an article ID, an article (original text), a number of words (in the article), a cleaned version of the text, the number of words (in the cleaned text), a publication date, a dominant topic in the article, the weight of the topic, a set of keywords related to the topic, and a topic label.\n",
    " \n",
    "#### Output:\n",
    "\n",
    "The code displays several plots and heatmaps to illustrate the results of each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the output folder where all the outputs will be saved\n",
    "output_path = \"/project_data/data_asset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 6\n",
    "\n",
    "articles = pd.read_csv(f\"{output_path}/ws_2_article_topic_{num_topics}.csv\")\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Number of articles published every day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_per_day = articles[[\"date\", \"topic_label\"]].copy()\n",
    "articles_per_day[\"n_articles\"] = 1\n",
    "articles_per_day = articles_per_day.groupby(\"date\").agg({\n",
    "    \"topic_label\": lambda x: list(x),\n",
    "    \"n_articles\": lambda x: sum(x)\n",
    "}).reset_index(drop=False)\n",
    "articles_per_day[\"topic_label\"] = articles_per_day[\"topic_label\"].apply(lambda x: list(set(x)))\n",
    "articles_per_day[\"n_topics\"] = articles_per_day[\"topic_label\"].apply(len)\n",
    "articles_per_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_per_day.plot(x=\"date\", \n",
    "                      y=\"n_articles\", \n",
    "                      figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_window_length = 10\n",
    "\n",
    "articles_per_day_rolling = articles_per_day.copy()\n",
    "articles_per_day_rolling[\"n_articles\"] = articles_per_day_rolling[\"n_articles\"].rolling(window=rolling_window_length).mean()\n",
    "articles_per_day_rolling.plot(x=\"date\", \n",
    "                              y=\"n_articles\", \n",
    "                              figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Number of articles published every day, per topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = pd.read_csv(f\"{output_path}/ws_2_article_topic_{num_topics}.csv\",\n",
    "                         usecols=[\"topic_label\"])\n",
    "all_topics = all_topics[\"topic_label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_per_day[\"topic_occurrences\"] = articles_per_day[\"topic_label\"].apply(lambda x: [(elem, x.count(elem)) for elem in all_topics])\n",
    "for topic_name in all_topics:\n",
    "    articles_per_day[topic_name] = articles_per_day[\"topic_occurrences\"].apply(lambda x: [elem[1] for elem in x if elem[0] == topic_name])\n",
    "    articles_per_day[topic_name] = articles_per_day[topic_name].apply(lambda x: x[0] if len(x) > 0 else 0)\n",
    "articles_per_day.drop([\"topic_label\", \"n_articles\", \"n_topics\", \"topic_occurrences\"], axis=1, inplace=True)\n",
    "articles_per_day.set_index(\"date\", drop=True, inplace=True)\n",
    "articles_per_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_window_length = 14\n",
    "\n",
    "df_heatmap = articles_per_day.copy()\n",
    "\n",
    "for col in df_heatmap.columns:\n",
    "    \n",
    "    # Normalise the results\n",
    "    m = max(df_heatmap[col].values)\n",
    "    df_heatmap[col] = 100 * df_heatmap[col] / m\n",
    "    \n",
    "    # Apply rolling window\n",
    "    df_heatmap[col] = df_heatmap[col].rolling(window=rolling_window_length).mean()\n",
    "\n",
    "df_heatmap.index = pd.to_datetime(df_heatmap.index.values).strftime('%b %d')\n",
    "df_heatmap = df_heatmap.iloc[rolling_window_length-1:, :]\n",
    "df_heatmap = df_heatmap.T\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "fig=plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.heatmap(df_heatmap, cmap=sns.color_palette(\"OrRd\", 50))\n",
    "\n",
    "plt.savefig(f\"{output_path}/plot_topic_{num_topics}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Sentiments conveyed in the articles published every day, per topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = pd.read_csv(f\"{output_path}/ws2_3_sentiment.csv\")\n",
    "sentiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "articles_polarity = pd.merge(articles, sentiments[[\"article_id\", \"polarity\"]], on=\"article_id\", how=\"left\")\n",
    "articles_polarity = articles_polarity[['article_id', 'date', 'polarity', 'topic_label']]\n",
    "articles_polarity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_polarity.hist(\"polarity\", bins=100, figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_per_day = articles_polarity[[\"date\", \"topic_label\", \"polarity\"]].copy()\n",
    "articles_per_day = articles_per_day.groupby([\"date\", \"topic_label\"]).agg({\n",
    "    \"polarity\": lambda x: np.mean(list(x))\n",
    "}).reset_index(drop=False)\n",
    "articles_per_day.rename(columns={\"polarity\": \"avg_polarity\"}, inplace=True)\n",
    "\n",
    "articles_per_day = articles_per_day.groupby(\"date\").agg({\n",
    "    \"topic_label\": lambda x: list(x),\n",
    "    \"avg_polarity\": lambda x: list(x)\n",
    "}).reset_index(drop=False)\n",
    "\n",
    "articles_per_day[\"zip\"] = articles_per_day.apply(lambda row: list(zip(row[\"topic_label\"], row[\"avg_polarity\"])), axis=1)\n",
    "\n",
    "for topic_name in all_topics:\n",
    "    articles_per_day[topic_name] = articles_per_day[\"zip\"].apply(lambda x: [elem[1] for elem in x if elem[0] == topic_name])\n",
    "    articles_per_day[topic_name] = articles_per_day[topic_name].apply(lambda x: x[0] if len(x) > 0 else 0)\n",
    "articles_per_day.drop([\"topic_label\", \"avg_polarity\", \"zip\"], axis=1, inplace=True)\n",
    "\n",
    "articles_per_day.set_index(\"date\", drop=True, inplace=True)\n",
    "\n",
    "articles_per_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_window_length = 14\n",
    "\n",
    "df_heatmap = articles_per_day.copy()\n",
    "\n",
    "for col in df_heatmap.columns:\n",
    "    \n",
    "    # Normalise the results\n",
    "    m = max(df_heatmap[col].values)\n",
    "    df_heatmap[col] = 100 * df_heatmap[col] / m\n",
    "    \n",
    "    # Apply rolling window\n",
    "    df_heatmap[col] = df_heatmap[col].rolling(window=rolling_window_length).mean()\n",
    "\n",
    "df_heatmap.index = pd.to_datetime(df_heatmap.index.values).strftime('%b %d')\n",
    "df_heatmap = df_heatmap.iloc[rolling_window_length-1:, :]\n",
    "df_heatmap = df_heatmap.T\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "fig=plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.heatmap(df_heatmap, cmap=sns.color_palette(\"BrBG\", 50))\n",
    "\n",
    "plt.savefig(f\"{output_path}/plot_sentiments_{num_topics}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authors\n",
    "  \n",
    "* **Vincent Nelis** is Senior Data Scientist with Data Science & AI Elite team where he specializes in Data Science, Analytics platforms, and Machine Learning solutions.\n",
    "* **Mehrnoosh Vahdat** is Data Scientist with Data Science & AI Elite team where she specializes in Data Science, Analytics platforms, and Machine Learning solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Â© IBM Corp. 2020. Licensed under the Apache License, Version 2.0. Released as licensed Sample Materials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
